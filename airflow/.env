# Variables:

AIRFLOW_VAR_MINIO_HOST=http://minio:9000
AIRFLOW_VAR_MINIO_ACCESS_KEY=AccessKey123
AIRFLOW_VAR_MINIO_SECRET_KEY=SecretKey123

AIRFLOW_VAR_DBT_HOST=postgres
AIRFLOW_VAR_DBT_USER=admin
AIRFLOW_VAR_DBT_PASSWORD=admin
AIRFLOW_VAR_DBT_PORT=5432
AIRFLOW_VAR_DBT_NAME=Adventureworks
AIRFLOW_VAR_DBT_SCHEMA=public

AIRFLOW_CONN_SPARK={"conn_type": "spark_connect", "description": "", "login": "", "password": null, "host": "sc://spark-connect", "port": null, "schema": "", "extra": "{\"use_ssl\": false}"}


# AIRFLOW_IMAGE_NAME="airflow-local:2.8.1"
# Meta-Database
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB=airflow


AIRFLOW__WEBSERVER__SHOW_TRIGGER_FORM_IF_NO_PARAMS=True

# Parallelism
AIRFLOW__CORE__PARALLELISM=5
AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG=3
AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG=1

# Airflow Core
AIRFLOW__CORE__FERNET_KEY=UKMzEm3yIuFYEq1y3-2FxPNWSVwRASpahmQ9kQfEr8E=
AIRFLOW__CORE__EXECUTOR=LocalExecutor
AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
AIRFLOW__CORE__LOAD_EXAMPLES=False
AIRFLOW_UID=1000

# Backend DB
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
AIRFLOW__DATABASE__LOAD_DEFAULT_CONNECTIONS=False

# Airflow Init
_AIRFLOW_DB_UPGRADE=True
_AIRFLOW_WWW_USER_CREATE=True
_AIRFLOW_WWW_USER_USERNAME=airflow
_AIRFLOW_WWW_USER_PASSWORD=airflow

# Use simple http server on scheduler for health checks
# See https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/check-health.html#scheduler-health-check-server
AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK=True

# AIRFLOW__API__AUTH_BACKENDS='airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session'

# WARNING: Use _PIP_ADDITIONAL_REQUIREMENTS option ONLY for a quick checks
# for other purpose (development, test and especially production usage) build/extend Airflow image.
# _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}